{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/nfip_claims_ML.csv\")\n",
    "df.drop([\"amountPaidonTotalClaim\", \"yearOfLoss\", \"originalConstructionDate\", \"Unnamed: 0\", \"floodZone\", \"LossRatio\", \"amountPaidOnBuildingClaim\", \"amountPaidOnContentsClaim\", \"amountPaidOnIncreasedCostOfComplianceClaim\"], inplace=True, axis=1)\n",
    "df.claim_segmentation = [0 if x==1 else 1 for x in df.claim_segmentation]\n",
    "# create lists of features that need encoding or scaling\n",
    "cat_features = list(df.select_dtypes(exclude=\"number\").columns)\n",
    "num_features = list(df.select_dtypes(include=\"number\").columns)\n",
    "num_features.remove(\"claim_segmentation\")\n",
    "# create a column transformer out of a scaler for the numerical and an encoder for the categorical columns \n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", scaler, num_features),\n",
    "    (\"cat\", encoder, cat_features)\n",
    "])\n",
    "# build pipe and name its components\n",
    "pipe = Pipeline([\n",
    "(\"preprocessor\", preprocessor),\n",
    "(\"clf\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# train test split\n",
    "y = df.pop(\"claim_segmentation\")\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "X_train_samp = X_train.sample(frac=0.1, random_state=42)\n",
    "y_train_samp = y_train[X_train_samp.index]\n",
    "# define params for random search\n",
    "rs_params={\"clf__max_depth\": list(np.arange(10, 100, step=10)) + [None],\n",
    "              \"clf__n_estimators\": np.arange(50, 500, step=50),\n",
    "              \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
    "              \"clf__criterion\": [\"gini\",\"entropy\"],\n",
    "              \"clf__min_samples_leaf\": np.arange(1, 10),\n",
    "              \"clf__min_samples_split\": np.arange(2, 10, step=2)\n",
    "          }\n",
    "# define randomized search\n",
    "rand = RandomizedSearchCV(pipe, rs_params, n_iter=200, scoring=[\"f1_weighted\", \"accuracy\"], cv=5, n_jobs=-1, random_state=42, verbose=5, refit=\"f1_weighted\")\n",
    "# run randomized search\n",
    "rand.fit(X_train_samp, y_train_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.76\n",
      "Best parameters:\n",
      "{'clf__n_estimators': 400, 'clf__min_samples_split': 6, 'clf__min_samples_leaf': 5, 'clf__max_features': 'log2', 'clf__max_depth': 70, 'clf__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# show best parameters\n",
    "print(\"Best score:\\n{:.2f}\".format(rand2.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rand2.best_params_))\n",
    "# create a results dataframe from the results dict of the classifier\n",
    "result_df_rand2 = pd.DataFrame.from_dict(rand2.cv_results_, orient=\"columns\")\n",
    "\n",
    "# plot some results, e.g.\n",
    "sns.relplot(data=result_df_rand,\n",
    "            kind=\"line\",\n",
    "            x=\"param_clf__n_estimators\",\n",
    "            y=\"mean_test_score\",\n",
    "            #col=\"clf__criterion\",\n",
    "            hue=\"param_clf__max_features\"\n",
    "            )\n",
    "plt.show()\n",
    "\n",
    "result_df_rand2.to_csv(\"../data/random_search_results_with_geo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_clf__min_samples_split</th>\n",
       "      <th>param_clf__min_samples_leaf</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10504.179758</td>\n",
       "      <td>29.86041</td>\n",
       "      <td>42.638269</td>\n",
       "      <td>4.813891</td>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>70</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'clf__n_estimators': 400, 'clf__min_samples_s...</td>\n",
       "      <td>0.765917</td>\n",
       "      <td>0.766273</td>\n",
       "      <td>0.766011</td>\n",
       "      <td>0.765936</td>\n",
       "      <td>0.766007</td>\n",
       "      <td>0.766029</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0   10504.179758      29.86041        42.638269        4.813891   \n",
       "\n",
       "  param_clf__n_estimators param_clf__min_samples_split  \\\n",
       "0                     400                            6   \n",
       "\n",
       "  param_clf__min_samples_leaf param_clf__max_features param_clf__max_depth  \\\n",
       "0                           5                    log2                   70   \n",
       "\n",
       "  param_clf__criterion                                             params  \\\n",
       "0                 gini  {'clf__n_estimators': 400, 'clf__min_samples_s...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.765917           0.766273           0.766011           0.765936   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.766007         0.766029        0.000128                1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params for grid search, based on random search results\n",
    "gs_params = {\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid search\n",
    "grid = GridSearchCV(pipe, param_grid=gs_params, cv=5, scoring=ftwo_scorer, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best parameters\n",
    "print(\"Best score:\\n{:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "best_model = grid.best_estimator_\n",
    "filename = \"finalized_model.sav\"\n",
    "pickle.dump(best_model, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4444930a2b1dff6f311b68d007563b18bf180f6c8e4dc63743b56591a741c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

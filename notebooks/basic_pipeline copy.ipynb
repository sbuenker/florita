{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/nfip_claims_ML.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"amountPaidonTotalClaim\", \"yearOfLoss\", \"originalConstructionDate\", \"Unnamed: 0\", \"floodZone\", \"LossRatio\", \"amountPaidOnBuildingClaim\", \"amountPaidOnContentsClaim\", \"amountPaidOnIncreasedCostOfComplianceClaim\", \"reportedZipcode\", \"latitude\", \"longitude\", \"countyCode\"], inplace=True, axis=1)\n",
    "df.claim_segmentation = [0 if x==1 else 1 for x in df.claim_segmentation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df, drop_first=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/claims_dummied.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.claim_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the next cell, make sure to remove the target column from the appropiate list! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of features that need encoding or scaling\n",
    "cat_features = list(df.select_dtypes(exclude=\"number\").columns)\n",
    "num_features = list(df.select_dtypes(include=\"number\").columns)\n",
    "num_features.remove(\"claim_segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column transformer out of a scaler for the numerical and an encoder for the categorical columns \n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", scaler, num_features),\n",
    "    (\"cat\", encoder, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipe and name its components\n",
    "pipe = Pipeline([\n",
    "(\"preprocessor\", preprocessor),\n",
    "(\"clf\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove cell/adjust target name as appropiate! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "y = df.pop(\"claim_segmentation\")\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fbeta scorer\n",
    "#ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params for random search\n",
    "rs_params={\"clf__max_depth\": list(np.arange(10, 100, step=10)) + [None],\n",
    "              \"clf__n_estimators\": np.arange(50, 250, step=50),\n",
    "              \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
    "              \"clf__criterion\": [\"gini\",\"entropy\"],\n",
    "              \"clf__min_samples_leaf\": np.arange(2, 10),\n",
    "              \"clf__min_samples_split\": np.arange(2, 10, step=2)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define randomized search\n",
    "rand = RandomizedSearchCV(pipe, rs_params, n_iter=1, scoring=\"accuracy\", cv=5, n_jobs=-1, random_state=42, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "rand.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best parameters\n",
    "print(\"Best score:\\n{:.2f}\".format(rand.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rand.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a results dataframe from the results dict of the classifier\n",
    "result_df_rand = pd.DataFrame.from_dict(rand.cv_results_, orient=\"columns\")\n",
    "\n",
    "# plot some results, e.g.\n",
    "sns.relplot(data=result_df_rand,\n",
    "            kind=\"line\",\n",
    "            x=\"param_clf__n_estimators\",\n",
    "            y=\"mean_test_score\",\n",
    "            hue=\"param_clf__max_features\",\n",
    "            col=\"clf__criterion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_csv(\"../data/random_search_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params for grid search, based on random search results\n",
    "gs_params = {\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid search\n",
    "grid = GridSearchCV(pipe, param_grid=gs_params, cv=5, scoring=ftwo_scorer, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best parameters\n",
    "print(\"Best score:\\n{:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "best_model = grid.best_estimator_\n",
    "filename = \"finalized_model.sav\"\n",
    "pickle.dump(best_model, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4444930a2b1dff6f311b68d007563b18bf180f6c8e4dc63743b56591a741c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
